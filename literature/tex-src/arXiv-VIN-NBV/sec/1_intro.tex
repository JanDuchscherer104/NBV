\vspace{-1.25em}
\section{Introduction}
\label{sec:intro}
\vspace{-0.25em}

Acquiring 3D knowledge of an environment is often a crucial step for many robotics applications; e.g., a drone surveying a disaster zone to assist search and rescue efforts, or autonomous robots monitoring large construction and agricultural sites. 
Real-world environments contain diverse objects of varying sizes, occlusions, and geometries; such complexities currently require a slow dense scan \cite{furukawa2010towards, schonberger2016pixelwise, frahm2010building, agarwal2011building, bleyer2011patchmatch, furukawa2009accurate, goesele2007multi, strecha2004wide} to reconstruct the 3D scene effectively. However, in many search and rescue operations, where speed leads to successful outcomes, acquiring the 3D scene in the shortest time possible is critical. In large construction or agricultural sites, battery life can be a limiting factor, making long captures costly. These challenges motivated techniques for resource-efficient scanning and 3D reconstruction, where constraints such as the number of captures, travel distance, or battery life must be respected. This problem has often been called the Next Best View (NBV) selection problem, where the goal is to predict a set of optimal camera viewpoints to maximize reconstruction quality.

Predicting NBVs is challenging due to the large search space for selecting the pose of each view, efficiently computing the optimal solution in this non-convex space, and the complexity of scene geometry and occlusions. Earlier works on NBV often assume prior knowledge of the scene (e.g., a preliminary scan or CAD model) \cite{devrim2017reinforcement,sun2021learning,zhang2021continuous,yan2021sampling, jing2016view, zhou2020offsite}, which limits applications in unexplored environments. Approaches that do not require prior knowledge of the scene predict NBVs by either maximizing coverage in the scene \cite{maver1993occlusions,roberts2017submodular,hepp2018learn,peralta2020next,guedon2022scone,guedon2023macarons} or by maximizing information gain \cite{hepp2018plan3d,zhang2021continuous,jiang2023fisherrf} in new viewpoints. While earlier methods have relied on heuristics or optimization \cite{maver1993occlusions,roberts2017submodular}, recent methods often train a deep reinforcement learning (RL) algorithm \cite{hepp2018learn,peralta2020next,hepp2018plan3d,zhang2021continuous,ran2023neurar,jiang2023fisherrf,9340916,chen2024gennbv} to maximize coverage. 

While maximizing coverage with RL \cite{chen2024gennbv,peralta2020next} may lead to a generalizable policy that can provide a good approximation of the scene, it ignores the fact that certain regions from the same scene may have more complicated geometry and self-occlusion. For example, in Fig.~\ref{fig:teaser}, if the fence of the house occludes a part of the wall, a single viewpoint capture may satisfy the coverage criterion, but will lead to a poor reconstruction with holes in the wall unless additional viewpoints are captured. Thus, our key idea is to develop an NBV acquisition policy that is trained to directly maximize the 3D reconstruction quality instead of only relying on a coverage criterion, which may fail to revisit areas with low coverage gains that will likely improve the reconstruction quality. Our policy design assumes the agent acquires RGB-D images and has no prior information about the scene.


We introduce a View Introspection Network (VIN) that can predict the relative reconstruction improvement (RRI) of any potential next view over the base images, without actually acquiring any image from the viewpoint. To demonstrate the effectiveness of directly optimizing reconstruction quality over coverage criterion, we design a simple, but effective, greedy sequential next best view selection policy VIN-NBV. At each acquisition step, the policy evaluates a set of uniformly sampled query views around the object, using the VIN to predict their effectiveness in improving reconstruction quality. The view that maximizes reconstruction improvement over base views is chosen. Our proposed VIN-NBV policy is generalizable to unseen object categories, and can operate under varying constraints, e.g. number of acquisitions, time traversed, and distance traversed; it can also avoid collisions.

The VIN is a lightweight neural network that takes the already captured base images, their camera parameters, and the query viewpoint camera parameters as input. The VIN performs a 3D-aware featurization of the already captured base views and then predicts a fitness score for each query view. We use the fitness score to indicate what Relative Reconstruction Improvement (RRI) over base views a query view may have. The VIN is trained using an imitation learning approach, where the RRI of all query viewpoints is pre-computed by explicitly reconstructing the scene with each query view and calculating the reduction in error.

We show that a relative reconstruction improvement (RRI) fitness criterion predicted by the VIN leads to ${\sim} 30\%$ improvement in reconstruction quality over a coverage fitness criterion, when using the same sampling-based greedy sequential strategy. We further show that the VIN-NBV policy significantly outperforms existing RL-based algorithms that aim to maximize coverage, reducing reconstruction error by 41\% compared to Scan-RL \cite{peralta2020next} and 39\% compared to GenNBV \cite{chen2024gennbv}.